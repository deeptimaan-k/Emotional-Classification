# ğŸ˜ƒ EmoSense â€“ Real-Time Emotion Detection System

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Stars](https://img.shields.io/github/stars/deeptimaan-k/EmoSense?style=social)](https://github.com/deeptimaan-k/EmoSense/stargazers)

**An AI-powered emotion recognition system that detects human emotions in real-time using Deep Learning and Computer Vision**

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#ï¸-installation--setup) â€¢ [Usage](#-usage) â€¢ [Model](#-model-architecture) â€¢ [Contributing](#-contributing)

<img src="https://img.shields.io/badge/Status-Active-success" alt="Status">
<img src="https://img.shields.io/badge/Maintained-Yes-brightgreen" alt="Maintained">

</div>

---

## ğŸ¯ Overview

**EmoSense** is an intelligent facial emotion recognition system that bridges the gap between human emotions and artificial intelligence. Built with TensorFlow, Keras, OpenCV, and Tkinter, it captures live webcam video, detects faces, and accurately predicts emotions in real-time.

The system employs a sophisticated CNN architecture trained on grayscale facial expression data to recognize **7 fundamental human emotions** with up to **90% accuracy**. Each prediction is accompanied by dynamic emoji reactions and personalized motivational messages, creating an engaging and interactive experience.

### ğŸŒŸ Why EmoSense?

- **Real-time Processing**: Instant emotion detection with minimal latency
- **High Accuracy**: Deep learning model achieving 85-90% accuracy
- **User-Friendly**: Intuitive Tkinter GUI requiring no technical expertise
- **Offline & Secure**: All processing happens locally on your device
- **Cross-Platform**: Works seamlessly on Windows, macOS, and Linux
- **Lightweight**: Optimized for performance on standard hardware

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¥ Core Features
- âœ… **Real-time webcam emotion detection**
- âœ… **Deep CNN model with 7 emotion classes**
- âœ… **Haar Cascade face detection**
- âœ… **Confidence score display**
- âœ… **Smooth prediction averaging**
- âœ… **Graceful error handling**

</td>
<td width="50%">

### ğŸ¨ Interface Features
- âœ… **Modern dual-panel Tkinter GUI**
- âœ… **Dynamic emoji reactions**
- âœ… **Motivational message system**
- âœ… **Responsive centered layout**
- âœ… **Real-time video visualization**
- âœ… **OS-optimized performance**

</td>
</tr>
</table>

---

## ğŸ­ Supported Emotions

<div align="center">

| Emotion | Emoji | AI Response | Color Code |
|---------|-------|-------------|------------|
| **Angry** ğŸ˜  | ğŸ”¥ | *"Take a deep breath and relax!"* | `#FF4444` |
| **Disgusted** ğŸ¤¢ | ğŸ˜£ | *"Something's bothering you?"* | `#8B4513` |
| **Fearful** ğŸ˜¨ | ğŸ˜± | *"Don't worry, everything will be fine!"* | `#9370DB` |
| **Happy** ğŸ˜€ | ğŸ˜ƒ | *"Keep smiling! You're doing great!"* | `#FFD700` |
| **Neutral** ğŸ˜ | ğŸ˜¶ | *"You seem calm and composed."* | `#A9A9A9` |
| **Sad** ğŸ˜” | ğŸ˜ | *"Cheer up! Better days are ahead."* | `#4682B4` |
| **Surprised** ğŸ˜² | ğŸ˜® | *"Wow! That's surprising!"* | `#FF6347` |

</div>

---

## ğŸ› ï¸ Tech Stack

<div align="center">

### Core Technologies

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

</div>

| Category | Technologies |
|----------|-------------|
| **Programming Language** | Python 3.8+ |
| **Deep Learning Framework** | TensorFlow 2.x, Keras |
| **Computer Vision** | OpenCV |
| **GUI Framework** | Tkinter, PIL (Pillow) |
| **Numerical Computing** | NumPy |
| **Data Augmentation** | ImageDataGenerator |
| **Model Type** | Convolutional Neural Network (CNN) |

---

## ğŸ“ Project Structure

```
ğŸ“¦ EmoSense/
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ train/              # Training dataset (7 emotion folders)
â”‚   â”‚   â”œâ”€â”€ angry/
â”‚   â”‚   â”œâ”€â”€ disgusted/
â”‚   â”‚   â”œâ”€â”€ fearful/
â”‚   â”‚   â”œâ”€â”€ happy/
â”‚   â”‚   â”œâ”€â”€ neutral/
â”‚   â”‚   â”œâ”€â”€ sad/
â”‚   â”‚   â””â”€â”€ surprised/
â”‚   â””â”€â”€ ğŸ“‚ test/               # Validation dataset
â”‚       â””â”€â”€ (same structure)
â”‚
â”œâ”€â”€ ğŸ“‚ emojis/                 # Emoji assets for each emotion
â”‚   â”œâ”€â”€ angry.png
â”‚   â”œâ”€â”€ disgusted.png
â”‚   â”œâ”€â”€ fearful.png
â”‚   â”œâ”€â”€ happy.png
â”‚   â”œâ”€â”€ neutral.png
â”‚   â”œâ”€â”€ sad.png
â”‚   â””â”€â”€ surprised.png
â”‚
â”œâ”€â”€ ğŸ“„ emotion_model.h5        # Trained model (architecture + weights)
â”œâ”€â”€ ğŸ“„ emotion_model.weights.h5 # Separate model weights
â”œâ”€â”€ ğŸ“„ haarcascade_frontalface_default.xml  # Face detection classifier
â”œâ”€â”€ ğŸ“„ main.py                 # Main application (GUI + detection)
â”œâ”€â”€ ğŸ“„ train_model.py          # Model training script
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ LICENSE                 # MIT License
â””â”€â”€ ğŸ“„ README.md              # Project documentation
```

---

## âš™ï¸ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- Webcam/Camera access
- 4GB RAM minimum (8GB recommended)
- 500MB free disk space

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/deeptimaan-k/EmoSense.git
cd EmoSense
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

**requirements.txt:**
```txt
tensorflow>=2.8.0
opencv-python>=4.5.0
numpy>=1.21.0
pillow>=9.0.0
tk
```

### 4ï¸âƒ£ Download Required Files

Ensure you have:
- `haarcascade_frontalface_default.xml` (included in OpenCV)
- `emotion_model.h5` (pre-trained model or train your own)
- Emoji assets in the `emojis/` folder

### 5ï¸âƒ£ (Optional) Train Your Own Model

If you want to train the model from scratch:

```bash
python train_model.py
```

**Dataset Structure Required:**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/      # 500+ images
â”‚   â”œâ”€â”€ disgusted/
â”‚   â”œâ”€â”€ fearful/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ neutral/
â”‚   â”œâ”€â”€ sad/
â”‚   â””â”€â”€ surprised/
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

---

## ğŸš€ Usage

### Running the Application

```bash
python main.py
```

### How It Works

1. **Launch Application**: The GUI window opens with dual panels
2. **Camera Activation**: Webcam automatically activates
3. **Face Detection**: Haar Cascade detects faces in real-time
4. **Emotion Prediction**: CNN model predicts emotion with confidence score
5. **Visual Feedback**: Displays emotion, emoji, and motivational message

### Keyboard Shortcuts

- `ESC` or `Q` - Exit application
- Window close button - Safe shutdown

---

## ğŸ§  Model Architecture

### CNN Architecture Details

```python
Model: Sequential CNN for Emotion Recognition
_________________________________________________________________
Layer (type)                Output Shape              Params
=================================================================
Conv2D (32 filters, 3x3)   (None, 46, 46, 32)        320
Conv2D (64 filters, 3x3)   (None, 44, 44, 64)        18,496
MaxPooling2D (2x2)          (None, 22, 22, 64)        0
Dropout (0.25)              (None, 22, 22, 64)        0
_________________________________________________________________
Conv2D (128 filters, 3x3)  (None, 20, 20, 128)       73,856
Conv2D (128 filters, 3x3)  (None, 18, 18, 128)       147,584
MaxPooling2D (2x2)          (None, 9, 9, 128)         0
Dropout (0.25)              (None, 9, 9, 128)         0
_________________________________________________________________
Flatten                     (None, 10368)             0
Dense (1024 units)          (None, 1024)              10,617,856
Dropout (0.5)               (None, 1024)              0
Dense (7 units, softmax)    (None, 7)                 7,175
=================================================================
Total params: 10,865,287
Trainable params: 10,865,287
```

### Training Configuration

- **Loss Function**: Categorical Crossentropy
- **Optimizer**: Adam (lr=0.0001, decay=1e-6)
- **Batch Size**: 64
- **Epochs**: 50 (with early stopping)
- **Image Size**: 48x48 pixels (grayscale)
- **Data Augmentation**: Rotation, shift, zoom, horizontal flip

### Performance Metrics

- **Training Accuracy**: ~90%
- **Validation Accuracy**: ~85-88%
- **Inference Speed**: 30-60 FPS (depending on hardware)
- **Model Size**: ~42 MB

---

## ğŸ–¼ï¸ Demo

### GUI Interface Preview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EmoSense - Emotion Detector              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              â”‚                              â”‚
â”‚   [ LIVE WEBCAM FEED ]       â”‚   Detected Emotion:          â”‚
â”‚                              â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   ğŸ˜€ Happy                   â”‚
â”‚   â”‚   [Face detected]   â”‚    â”‚                              â”‚
â”‚   â”‚   with bounding box â”‚    â”‚   Confidence: 96.3%          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                              â”‚
â”‚                              â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   Real-time processing...    â”‚   â”‚   [Emoji: ğŸ˜ƒ]    â”‚        â”‚
â”‚                              â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                              â”‚                              â”‚
â”‚                              â”‚   "Keep smiling! You're      â”‚
â”‚                              â”‚    doing great!"             â”‚
â”‚                              â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Outputs

**Input**: Person smiling at webcam  
**Output**:
- Emotion: Happy ğŸ˜€
- Confidence: 96.3%
- Message: "Keep smiling! You're doing great!"

**Input**: Person with furrowed brows  
**Output**:
- Emotion: Angry ğŸ˜ 
- Confidence: 89.7%
- Message: "Take a deep breath and relax!"

---

## ğŸ›¡ï¸ Error Handling

EmoSense includes robust error handling for:

- âœ… Camera access failures
- âœ… Model loading errors
- âœ… Missing emoji assets
- âœ… Face detection failures (displays "No Face Detected")
- âœ… Invalid frame captures
- âœ… Prediction smoothing to reduce jitter
- âœ… Graceful exit on exceptions

---

## ğŸŒ Cross-Platform Support

| Operating System | Support | Tested | Notes |
|-----------------|---------|--------|-------|
| ğŸªŸ Windows 10/11 | âœ… Full | âœ… Yes | Optimized camera access |
| ğŸ macOS | âœ… Full | âœ… Yes | AVFoundation support |
| ğŸ§ Linux | âœ… Full | âœ… Yes | V4L2 compatible |

---

## ğŸš€ Future Enhancements

### Planned Features

- ğŸ”¹ **Emotion-based music recommendations** using Spotify API
- ğŸ”¹ **Voice feedback system** with text-to-speech
- ğŸ”¹ **Cloud analytics dashboard** for emotion tracking over time
- ğŸ”¹ **Multi-face detection** for group emotion analysis
- ğŸ”¹ **IoT integration** for smart home mood lighting
- ğŸ”¹ **Mobile app version** using React Native + TensorFlow Lite
- ğŸ”¹ **Export emotion logs** to CSV/JSON
- ğŸ”¹ **Custom emotion training** interface

### Research & Development

- ğŸ“Š Micro-expression detection
- ğŸ¯ Context-aware emotion understanding
- ğŸ§¬ Personalized emotion baselines
- ğŸŒ Multi-cultural emotion recognition

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### How to Contribute

1. **Fork the repository**
2. **Create your feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit your changes**
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```
4. **Push to the branch**
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Open a Pull Request**

### Contribution Guidelines

- Follow PEP 8 style guide for Python code
- Add unit tests for new features
- Update documentation as needed
- Ensure all tests pass before submitting PR

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

You are free to:
- âœ… Use commercially
- âœ… Modify
- âœ… Distribute
- âœ… Private use

With the requirement to include the original license and copyright notice.

---

## ğŸ‘¨â€ğŸ’» Author

<div align="center">

### Deeptimaan K

[![GitHub](https://img.shields.io/badge/GitHub-deeptimaan--k-181717?style=for-the-badge&logo=github)](https://github.com/deeptimaan-k)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/deeptimaan-k)

**"Emotions speak louder than words â€” now, your computer understands them too."** ğŸ§ ğŸ’«

</div>

---

## ğŸ™ Acknowledgments

- **FER-2013 Dataset** for training data
- **OpenCV** community for computer vision tools
- **TensorFlow/Keras** team for the deep learning framework
- All contributors and supporters of this project

---

## â­ Show Your Support

If you found this project helpful or interesting, please consider:

- â­ **Starring** this repository
- ğŸ´ **Forking** it for your own experiments
- ğŸ› **Reporting bugs** to help improve it
- ğŸ’¡ **Suggesting new features**
- ğŸ“¢ **Sharing** with others who might benefit

<div align="center">

### Made with â¤ï¸ by [deeptimaan-k](https://github.com/deeptimaan-k)

**Star â­ this repository if it helped you!**

[![GitHub Stars](https://img.shields.io/github/stars/deeptimaan-k/EmoSense?style=social)](https://github.com/deeptimaan-k/EmoSense/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/deeptimaan-k/EmoSense?style=social)](https://github.com/deeptimaan-k/EmoSense/network/members)
[![GitHub Watchers](https://img.shields.io/github/watchers/deeptimaan-k/EmoSense?style=social)](https://github.com/deeptimaan-k/EmoSense/watchers)

</div>

---

<div align="center">

**Questions or suggestions?** [Open an issue](https://github.com/deeptimaan-k/EmoSense/issues) or reach out!

</div>
